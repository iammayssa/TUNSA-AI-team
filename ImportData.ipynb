{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bf6EnAFlpTQv"
      },
      "source": [
        "#Import Datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x6u2-7vnXTQG"
      },
      "source": [
        "##Kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ycsth75yXOgn",
        "outputId": "6991d2df-9819-4e9e-a25f-9c099fae6e62"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.7/dist-packages (1.5.12)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from kaggle) (1.24.3)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.7/dist-packages (from kaggle) (1.15.0)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.7/dist-packages (from kaggle) (6.1.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from kaggle) (2021.10.8)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from kaggle) (4.63.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from kaggle) (2.23.0)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle) (3.0.4)\n"
          ]
        }
      ],
      "source": [
        "! pip install kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GhtQ4jEjXhns"
      },
      "outputs": [],
      "source": [
        "! mkdir ~/.kaggle\n",
        "! cp kaggle.json ~/.kaggle/\n",
        "! chmod 600 ~/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ayu1p2WDX3Pm"
      },
      "outputs": [],
      "source": [
        "! kaggle competitions download <name-of-competition>\n",
        "! kaggle datasets download <name-of-dataset>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7EX8DhtsX8wb"
      },
      "source": [
        "##Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eDuvXRqxX8UA",
        "outputId": "2e618582-6886-4255-f7c7-f107ada7e071"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/gdrive\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U7MgO8FcYej4"
      },
      "source": [
        "##Tensorflow_datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Bqu7yKjYeTE"
      },
      "outputs": [],
      "source": [
        "import tensorflow_datasets as tfds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4bU1BecrK0lX"
      },
      "outputs": [],
      "source": [
        "tfds."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oQEVkbveY1yD"
      },
      "outputs": [],
      "source": [
        "(train_data, test_data), info = tfds.load(name='imdb_reviews/subwords8k', split=(tfds.Split.TRAIN, tfds.Split.TEST), \n",
        "                            with_info=True,\n",
        "                            as_supervised=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-yyqWoFlu_2B"
      },
      "source": [
        "##Utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "p1lWE0urvCe5"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import zipfile\n",
        "\n",
        "local_zip = '/content/gdrive/MyDrive/Images.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('/content/cell_images')\n",
        "zip_ref.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s-rK7Kg0pOIR"
      },
      "source": [
        "#Feed data to the Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5bw_sRhlpcRe"
      },
      "source": [
        "##Data Generator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KgvQUEQepbVm"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import keras_preprocessing\n",
        "from keras_preprocessing import image\n",
        "from keras_preprocessing.image import ImageDataGenerator\n",
        "\n",
        "TRAINING_DIR = \"/content/train/train\"\n",
        "training_datagen = ImageDataGenerator(\n",
        "      rescale = 1./255,\n",
        "\t    rotation_range=40,\n",
        "      width_shift_range=0.2,\n",
        "      height_shift_range=0.2,\n",
        "      shear_range=0.2,\n",
        "      zoom_range=0.2,\n",
        "      horizontal_flip=True,\n",
        "      fill_mode='nearest')\n",
        "\n",
        "VALIDATION_DIR = \"/content/val/validation\"\n",
        "validation_datagen = ImageDataGenerator(rescale = 1./255)\n",
        "\n",
        "train_generator = training_datagen.flow_from_directory(\n",
        "\tTRAINING_DIR,\n",
        "\ttarget_size=(224,224),\n",
        "\tclass_mode='categorical',\n",
        "  batch_size=126\n",
        ")\n",
        "\n",
        "validation_generator = validation_datagen.flow_from_directory(\n",
        "\tVALIDATION_DIR,\n",
        "\ttarget_size=(224,224),\n",
        "\tclass_mode='categorical',\n",
        "  batch_size=126\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U319TlpnqHMP"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "def generator(samples, batch_size=32,resize=224):\n",
        "    \"\"\"\n",
        "    Yields the next training batch.\n",
        "    Suppose `samples` is an array [[image1_filename,label1], [image2_filename,label2],...].\n",
        "    \"\"\"\n",
        "    \n",
        "    num_samples = len(samples)\n",
        "    while True: # Loop forever so the generator never terminates\n",
        "\n",
        "        # Get index to start each batch: [0, batch_size, 2*batch_size, ..., max multiple of batch_size <= num_samples]\n",
        "        \n",
        "        for offset in range(0, num_samples, batch_size):\n",
        "            # Get the samples you'll use in this batch\n",
        "            batch_samples = samples[offset:offset+batch_size].values.tolist()\n",
        "            \n",
        "            # Initialise X_train and y_train arrays for this batch\n",
        "            X_train = []\n",
        "            y_train = []\n",
        "            \n",
        "            # For each example\n",
        "            for batch_sample in batch_samples:\n",
        "                # Load image (X) and label (y)\n",
        "                img_name = batch_sample[0]\n",
        "                label = batch_sample[1:]\n",
        "                img =  cv2.imread(os.path.join(img_name))\n",
        "                \n",
        "                # apply any kind of preprocessing\n",
        "                img = cv2.resize(img,(resize,resize))\n",
        "                # Add example to arrays\n",
        "                X_train.append(img)\n",
        "                y_train.append(label)\n",
        "                \n",
        "            # Make sure they're numpy arrays (as opposed to lists)\n",
        "            X_train = np.array(X_train)\n",
        "            y_train = np.array(y_train)\n",
        "\n",
        "            # The generator-y part: yield the next training batch            \n",
        "            yield X_train, y_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DOVXhZ3RuU9C"
      },
      "outputs": [],
      "source": [
        "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "  data_dir,\n",
        "  validation_split=0.3,\n",
        "  subset=\"training\",\n",
        "  seed=123,\n",
        "  image_size=(img_height, img_width),\n",
        "  batch_size=batch_size)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "ImportData.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}